{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### user entries\n",
    "\n",
    "min_match_len = 3\n",
    "\n",
    "min_match_rate = .5\n",
    "\n",
    "beg_end_str_char = \"|\"\n",
    "\n",
    "value_split_char = \",\"\n",
    "\n",
    "# user_match_entry = \"asdkjhsehtestdfhgytrehehddoggydlgiqwertyguthd, 123234345test45qwerty65675678doggy2434534, sqwertydftestsdftestsdfdoggysdfdoggysdf, asqwertydfheuyhtestsdfkjehykuydoggysdfgsjgfhjf, sdqwertysdftestddddoggyddd, sdfgteqwertyfgftestsdfefhjdoggysdfhjf\"\n",
    "user_match_entry = \"Discectomy, Laminectomy, Foraminotomy, Corpectomy, Spinal (Lumbar) Fusion, Spinal Cord Stimulation\"\n",
    "\n",
    "user_nope_match_entry = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_denominator(min_match_len: int, min_match_rate: float, beg_end_str_char: str, value_split_char: str, user_match_entry: str, user_nope_match_entry: str):\n",
    "\n",
    "    # process user_match_entry\n",
    "    var_list = user_match_entry.split(value_split_char)\n",
    "    var_list = list(map(lambda x: x.strip(), var_list))\n",
    "    for ind, val in enumerate(var_list):\n",
    "        var_list[ind] = beg_end_str_char + var_list[ind] + beg_end_str_char\n",
    "    var_list = list(map(lambda x: x.lower().strip(), var_list))\n",
    "    # var_list\n",
    "\n",
    "    # process user_no_match_entry\n",
    "    var_nope_list = user_nope_match_entry.split(value_split_char)\n",
    "    var_nope_list = list(map(lambda x: x.strip(), var_nope_list))\n",
    "    for ind, val in enumerate(var_nope_list):\n",
    "        var_nope_list[ind] = beg_end_str_char + var_nope_list[ind] + beg_end_str_char\n",
    "    var_nope_list = list(map(lambda x: x.lower().strip(), var_nope_list))\n",
    "    # var_nope_list\n",
    "\n",
    "    # create the dict of all word segments\n",
    "    # and a master list of all segments from all words\n",
    "    var_dict = {}\n",
    "    master_ref_list = set()\n",
    "\n",
    "    for word in var_list:\n",
    "        test_set = set()\n",
    "        for start in range(len(word)):\n",
    "            for end in range(1, len(word)+1):\n",
    "                if start > end:\n",
    "                    pass\n",
    "                if len(word[start:end]) < min_match_len:\n",
    "                    pass\n",
    "                else:\n",
    "                    test_set.add((word[start:end].strip()))\n",
    "                    master_ref_list.add((word[start:end].strip()))\n",
    "        var_dict[word] = test_set\n",
    "    # master_ref_list\n",
    "\n",
    "    # create the dict of all word segments - for nope list\n",
    "    # and a master list of all segments from all words - for nope list\n",
    "    var_nope_dict = {}\n",
    "    master_nope_ref_list = set()\n",
    "\n",
    "    for word in var_nope_list:\n",
    "        test_set = set()\n",
    "        for start in range(len(word)):\n",
    "            for end in range(1, len(word)+1):\n",
    "                if start > end:\n",
    "                    pass\n",
    "                if len(word[start:end]) < min_match_len:\n",
    "                    pass\n",
    "                else:\n",
    "                    test_set.add((word[start:end].strip()))\n",
    "                    master_nope_ref_list.add((word[start:end].strip()))\n",
    "        var_nope_dict[word] = test_set\n",
    "    # master_nope_ref_list\n",
    "\n",
    "    triangle_dict = {}\n",
    "    for ind, val in enumerate(var_list):\n",
    "        triangle_dict[ind+1] = (ind)*(ind+1)//2\n",
    "    # triangle_dict\n",
    "\n",
    "    triangle_dict_reverse = {}\n",
    "    for ind, val in enumerate(var_list):\n",
    "        triangle_dict_reverse[(ind)*(ind+1)//2] = ind+1\n",
    "    # triangle_dict_reverse\n",
    "\n",
    "    min_match_number = triangle_dict[math.ceil(len(var_list)*min_match_rate)]\n",
    "    # min_match_number\n",
    "\n",
    "\n",
    "    # # pass 3: everything compared against the previous\n",
    "    # # this should make the final full dict ranking better\n",
    "\n",
    "    final_match_dict = {}\n",
    "    for i in master_ref_list:\n",
    "        final_match_dict[i] = 0\n",
    "    x = 0\n",
    "\n",
    "    for first_ind, first_val in enumerate(var_list):\n",
    "        for second_ind, second_val in enumerate(var_list):\n",
    "            if first_ind <= second_ind:\n",
    "                pass\n",
    "            else:\n",
    "                for first in var_dict[var_list[first_ind]]:\n",
    "                    for second in var_dict[var_list[second_ind]]:\n",
    "                        x+=1\n",
    "                        if first == second:\n",
    "                            try:\n",
    "                                final_match_dict[first] += 1\n",
    "                            except:\n",
    "                                pass\n",
    "\n",
    "\n",
    "    final_match_list = []\n",
    "    for key, value in final_match_dict.items():\n",
    "        # if value == (len(var_list)-1)*len((var_list))//2:\n",
    "        if value >= min_match_number:\n",
    "            final_match_list.append(key)\n",
    "\n",
    "    # print(x)\n",
    "\n",
    "    final_match_list = sorted(final_match_list, key=len, reverse=True)\n",
    "\n",
    "    # remove values found in the nope list\n",
    "    final_match_list_temp = list(final_match_list)\n",
    "    for val in final_match_list_temp:\n",
    "        for nope_val in master_nope_ref_list:\n",
    "            if val == nope_val:\n",
    "                try:\n",
    "                    final_match_list.remove(val)\n",
    "                except:\n",
    "                    pass\n",
    "    # remove values found in the nope list\n",
    "    final_match_dict_temp = final_match_dict.copy()\n",
    "    for val in final_match_dict_temp:\n",
    "        for nope_val in master_nope_ref_list:\n",
    "            if val == nope_val:\n",
    "                try:\n",
    "                    del final_match_dict[val]\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "    # final_match_list\n",
    "\n",
    "    # cut out the smaller findings when there is a bigger chunk of text found\n",
    "    final_match_list_temp = final_match_list.copy()\n",
    "    x = 0\n",
    "    for pri in final_match_list_temp:\n",
    "        for sec in final_match_list_temp:\n",
    "            if pri.find(sec) > -1 and pri != sec:\n",
    "                try:\n",
    "                    final_match_list.remove(sec)\n",
    "                except:\n",
    "                    x += 1\n",
    "\n",
    "    # final_match_list\n",
    "\n",
    "    # first main return\n",
    "    # list of string parts that\n",
    "        # have a match rate greater than the set minimum\n",
    "        # are not part of a larger, also included string (e.g. if 'dog' is already included, 'og' will be excluded)\n",
    "    # a bigger word part will however knock off a smaller word part with a higher match rate\n",
    "\n",
    "\n",
    "    filtered_dict = dict()\n",
    "    for (key, value) in final_match_dict.items():\n",
    "        if value >= min_match_number:\n",
    "            filtered_dict[key] = round(triangle_dict_reverse[value]/len(var_list),4)\n",
    "\n",
    "    filtered_dict # maybe this one will be better to return in app?\n",
    "\n",
    "    final_df = pd.DataFrame.from_dict(filtered_dict, orient='index')\n",
    "    final_df = final_df.rename(columns={0:'Match Rate'})\n",
    "    final_df = final_df.sort_values(by=['Match Rate'], ascending=False)\n",
    "\n",
    "    # final_df\n",
    "\n",
    "    # second main return\n",
    "    # dictionary/df with all valid string parts and how often they match\n",
    "\n",
    "    return final_match_list, final_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ectomy|'],\n",
       "          Match Rate\n",
       " my|          0.6667\n",
       " tomy         0.6667\n",
       " omy|         0.6667\n",
       " tomy|        0.6667\n",
       " omy          0.6667\n",
       " tom          0.6667\n",
       " ctomy        0.5000\n",
       " ecto         0.5000\n",
       " ctom         0.5000\n",
       " ectomy       0.5000\n",
       " ectom        0.5000\n",
       " cto          0.5000\n",
       " ctomy|       0.5000\n",
       " ectomy|      0.5000\n",
       " ect          0.5000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_denominator(3, .5, \"|\", \",\", \"Discectomy, Laminectomy, Foraminotomy, Corpectomy, Spinal (Lumbar) Fusion, Spinal Cord Stimulation\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "413c54d42d867d78bc5693b88112002b4b75f03abc9fed1665b973f73c05d110"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
